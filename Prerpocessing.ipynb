{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.66.4)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags,strip_numeric, strip_punctuation, strip_multiple_whitespaces,remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "from transformers import BertTokenizer\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shashinimashi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = '/Users/shashinimashi/Desktop/Semester 3/Thesis/Analysis/Research_OAI-1/transcripts.csv'  \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>Supporting Responsible Ai Discussion Paper</td>\n",
       "      <td>The Australian Federal Police Afp Welcomes The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>507</td>\n",
       "      <td>Safe And Responsible Ai In Australia’</td>\n",
       "      <td>The Disr Have Called For Public Submissions To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506</td>\n",
       "      <td>Safe And Responsible Ai In Australia\\r\\nDiscus...</td>\n",
       "      <td>The Office Of The Australian Information Commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505</td>\n",
       "      <td>Canvas Approach To Ai</td>\n",
       "      <td>Canvas Mission Is To Empower The World To Desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>Safe And Responsible Ai In\\r\\nAustralia</td>\n",
       "      <td>The Law Council Welcomes The Opportunity To Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResponseID                                              Topic  \\\n",
       "0         510         Supporting Responsible Ai Discussion Paper   \n",
       "1         507              Safe And Responsible Ai In Australia’   \n",
       "2         506  Safe And Responsible Ai In Australia\\r\\nDiscus...   \n",
       "3         505                              Canvas Approach To Ai   \n",
       "4         504            Safe And Responsible Ai In\\r\\nAustralia   \n",
       "\n",
       "                                       Transcription  \n",
       "0  The Australian Federal Police Afp Welcomes The...  \n",
       "1  The Disr Have Called For Public Submissions To...  \n",
       "2  The Office Of The Australian Information Commi...  \n",
       "3  Canvas Mission Is To Empower The World To Desi...  \n",
       "4  The Law Council Welcomes The Opportunity To Pr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseID', 'Topic', 'Transcription'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of      ResponseID                                              Topic  \\\n",
       "0           510         Supporting Responsible Ai Discussion Paper   \n",
       "1           507              Safe And Responsible Ai In Australia’   \n",
       "2           506  Safe And Responsible Ai In Australia\\r\\nDiscus...   \n",
       "3           505                              Canvas Approach To Ai   \n",
       "4           504            Safe And Responsible Ai In\\r\\nAustralia   \n",
       "..          ...                                                ...   \n",
       "411           7  Epistemic Virtues Of Harnessing Rigorous\\r\\nMa...   \n",
       "412           6  Ai Explainability Framework For Environmental ...   \n",
       "413           4  Submission To Responsible Ai In Australia – Ga...   \n",
       "414           2  Ben Blackburn Racing Submission\\r\\nOn The Aust...   \n",
       "415           1                             Make A General Comment   \n",
       "\n",
       "                                         Transcription  \n",
       "0    The Australian Federal Police Afp Welcomes The...  \n",
       "1    The Disr Have Called For Public Submissions To...  \n",
       "2    The Office Of The Australian Information Commi...  \n",
       "3    Canvas Mission Is To Empower The World To Desi...  \n",
       "4    The Law Council Welcomes The Opportunity To Pr...  \n",
       "..                                                 ...  \n",
       "411  Some Physicians In Their Care Of\\r\\nPatients A...  \n",
       "412  Deep Learning Networks Powered By Ai Are Essen...  \n",
       "413  I Imported Zx80 Pc From Uk 43Yr Ago At 14Yr Ol...  \n",
       "414  I Am Extremely Pleased To Provide This Public ...  \n",
       "415  Ensure Ai Has Built In Prime Directives That C...  \n",
       "\n",
       "[416 rows x 3 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shashinimashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shashinimashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the column 'Transcription':\n",
      "0    The Australian Federal Police Afp Welcomes The...\n",
      "1    The Disr Have Called For Public Submissions To...\n",
      "2    The Office Of The Australian Information Commi...\n",
      "3    Canvas Mission Is To Empower The World To Desi...\n",
      "4    The Law Council Welcomes The Opportunity To Pr...\n",
      "Name: Transcription, dtype: object\n",
      "'Responses' column has been created successfully.\n",
      "                                       Transcription  \\\n",
      "0  The Australian Federal Police Afp Welcomes The...   \n",
      "1  The Disr Have Called For Public Submissions To...   \n",
      "2  The Office Of The Australian Information Commi...   \n",
      "3  Canvas Mission Is To Empower The World To Desi...   \n",
      "4  The Law Council Welcomes The Opportunity To Pr...   \n",
      "\n",
      "                                           Responses  \n",
      "0  [the australian federal police af ##p welcome ...  \n",
      "1  [the di ##sr have called for public submission...  \n",
      "2  [the office of the australian information comm...  \n",
      "3  [canvas mission is to em ##power the world to ...  \n",
      "4  [the law council welcome ##s the opportunity t...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from transformers import BertTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pandas as pd  \n",
    "\n",
    "# Download NLTK data for sentence tokenization (ensure 'punkt' is available)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def clean_and_tokenize(df, column_name='Transcription'):\n",
    "    \n",
    "    # Ensure the column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in the DataFrame.\")\n",
    "        return df\n",
    "    \n",
    "    def clean_text(text):\n",
    "        if not text or pd.isna(text):  # Check for empty or NaN values\n",
    "            return []  # Return an empty list if the text is invalid\n",
    "\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove HTML tags\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "        \n",
    "        # Tokenize the text using BERT tokenizer (subword-level)\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "        # Rejoin tokens into a single string\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "        \n",
    "        # Alternative sentence tokenization using re.split()\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', cleaned_text)\n",
    "        \n",
    "        return sentences\n",
    "\n",
    "    # Debug: Print first few rows before cleaning\n",
    "    print(f\"First few rows of the column '{column_name}':\")\n",
    "    print(df[column_name].head())\n",
    "    \n",
    "    # Apply the clean_text function to each entry in the column\n",
    "    df['Responses'] = df[column_name].apply(clean_text)\n",
    "    \n",
    "    # Debug: Check if the Responses column has been added\n",
    "    if 'Responses' in df.columns:\n",
    "        print(f\"'Responses' column has been created successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: 'Responses' column not created.\")\n",
    "    \n",
    "    # Print the DataFrame with Transcriptions and Responses\n",
    "    print(df[['Transcription', 'Responses']].head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_cleaned = clean_and_tokenize(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>Supporting Responsible Ai Discussion Paper</td>\n",
       "      <td>The Australian Federal Police Afp Welcomes The...</td>\n",
       "      <td>[the australian federal police af ##p welcome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>507</td>\n",
       "      <td>Safe And Responsible Ai In Australia’</td>\n",
       "      <td>The Disr Have Called For Public Submissions To...</td>\n",
       "      <td>[the di ##sr have called for public submission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506</td>\n",
       "      <td>Safe And Responsible Ai In Australia\\r\\nDiscus...</td>\n",
       "      <td>The Office Of The Australian Information Commi...</td>\n",
       "      <td>[the office of the australian information comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505</td>\n",
       "      <td>Canvas Approach To Ai</td>\n",
       "      <td>Canvas Mission Is To Empower The World To Desi...</td>\n",
       "      <td>[canvas mission is to em ##power the world to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>Safe And Responsible Ai In\\r\\nAustralia</td>\n",
       "      <td>The Law Council Welcomes The Opportunity To Pr...</td>\n",
       "      <td>[the law council welcome ##s the opportunity t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResponseID                                              Topic  \\\n",
       "0         510         Supporting Responsible Ai Discussion Paper   \n",
       "1         507              Safe And Responsible Ai In Australia’   \n",
       "2         506  Safe And Responsible Ai In Australia\\r\\nDiscus...   \n",
       "3         505                              Canvas Approach To Ai   \n",
       "4         504            Safe And Responsible Ai In\\r\\nAustralia   \n",
       "\n",
       "                                       Transcription  \\\n",
       "0  The Australian Federal Police Afp Welcomes The...   \n",
       "1  The Disr Have Called For Public Submissions To...   \n",
       "2  The Office Of The Australian Information Commi...   \n",
       "3  Canvas Mission Is To Empower The World To Desi...   \n",
       "4  The Law Council Welcomes The Opportunity To Pr...   \n",
       "\n",
       "                                           Responses  \n",
       "0  [the australian federal police af ##p welcome ...  \n",
       "1  [the di ##sr have called for public submission...  \n",
       "2  [the office of the australian information comm...  \n",
       "3  [canvas mission is to em ##power the world to ...  \n",
       "4  [the law council welcome ##s the opportunity t...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
