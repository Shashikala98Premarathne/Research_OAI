{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas transformers requests sentence-transformers\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\", add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load Preprocessed Data and Embeddings\n",
    "try:\n",
    "    df_cleaned = pd.read_csv(\"/Users/shashinimashi/Desktop/Semester 3/Thesis/Analysis/Repo/Research_OAI-4/df_cleaned.csv\")\n",
    "    with open(\"/Users/shashinimashi/Desktop/Semester 3/Thesis/Analysis/Repo/Research_OAI-4/response_embeddings.pkl\", \"rb\") as f:\n",
    "        response_embeddings = pickle.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: Missing required files. Ensure df_cleaned.csv and response_embeddings.pkl are available.\")\n",
    "    raise\n",
    "\n",
    "# Initialize SentenceTransformer Model\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Load the Local LLaMA Model\n",
    "TOKEN = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-70b-hf\", use_auth_token=TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-70b-hf\", use_auth_token=TOKEN)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def llama_generate_summary(input_text):\n",
    "    \"\"\"\n",
    "    Use the locally loaded LLaMA model to generate text based on the input prompt.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate output from the model\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=50, \n",
    "        temperature=0.7, \n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(query_embeddings, response_embeddings):\n",
    "    similarities = {}\n",
    "    for response_id, embedding in response_embeddings.items():\n",
    "        response_embedding_numpy = embedding.detach().cpu().numpy()  # Ensure tensor is on CPU\n",
    "        response_embedding_normalized = normalize(response_embedding_numpy.reshape(1, -1), axis=1)\n",
    "        max_similarity = max(\n",
    "            cosine_similarity(query_embeddings, response_embedding_normalized).flatten()\n",
    "        )\n",
    "        similarities[response_id] = max_similarity\n",
    "    return similarities\n",
    "\n",
    "# Main Function to Generate Mimicking Text\n",
    "def generate_mimicking_text(keyword1, keyword2):\n",
    "    if keyword1 or keyword2:\n",
    "        try:\n",
    "            user_keywords = [kw.strip() for kw in [keyword1, keyword2] if kw.strip()]\n",
    "\n",
    "            # Generate Embeddings for User Keywords\n",
    "            keyword_embeddings = embedding_model.encode(user_keywords, convert_to_tensor=True)\n",
    "            keyword_embeddings_cpu = normalize(keyword_embeddings.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "            # Calculate Cosine Similarity between User Keywords and Responses\n",
    "            response_similarities = {}\n",
    "            for response_id, embedding in response_embeddings.items():\n",
    "                response_similarities[response_id] = calculate_cosine_similarity(keyword_embeddings_cpu, {response_id: embedding})[response_id]\n",
    "\n",
    "            # Dynamic Grid Search to Find Best Threshold\n",
    "            threshold_range = np.arange(0.0, 1.01, 0.01)\n",
    "            best_threshold = None\n",
    "            best_rouge1_fmeasure = -float(\"inf\")\n",
    "            filtered_responses_best = None\n",
    "\n",
    "            for threshold in threshold_range:\n",
    "                # Filter Responses Based on Threshold\n",
    "                filtered_responses = {\n",
    "                    response_id: sim for response_id, sim in response_similarities.items() if sim >= threshold\n",
    "                }\n",
    "\n",
    "                if not filtered_responses:\n",
    "                    continue\n",
    "\n",
    "                # Combine Filtered Responses into a Single String\n",
    "                filtered_reference = \" \".join([\n",
    "                    df_cleaned.loc[df_cleaned['ResponseID'] == resp_id, 'Responses'].values[0]\n",
    "                    for resp_id in filtered_responses.keys()\n",
    "                ])\n",
    "\n",
    "                # Generate Mimicking Text with Local LLaMA Model\n",
    "                prompt = (\n",
    "                    f\"Analyze the following text to understand its language, structure, and style:\\n\\n\"\n",
    "                    f\"{filtered_reference}\\n\\n\"\n",
    "                    f\"Now generate new text that mimics the above language, structure, and style, \"\n",
    "                    f\"while introducing new content related to the keywords: {', '.join(user_keywords)}.\"\n",
    "                )\n",
    "                mimicked_text = llama_generate_summary(prompt)\n",
    "\n",
    "                # Evaluate Using ROUGE-1 F-Measure (optional)\n",
    "                from rouge_score import rouge_scorer\n",
    "                rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "                rouge_scores = rouge_scorer_instance.score(filtered_reference, mimicked_text)\n",
    "                rouge1_fmeasure = rouge_scores['rouge1'].fmeasure\n",
    "\n",
    "                # Update Best Threshold\n",
    "                if rouge1_fmeasure > best_rouge1_fmeasure:\n",
    "                    best_rouge1_fmeasure = rouge1_fmeasure\n",
    "                    best_threshold = threshold\n",
    "                    filtered_responses_best = filtered_responses\n",
    "\n",
    "            # Generate Final Mimicking Text Using Best Threshold\n",
    "            if filtered_responses_best:\n",
    "                final_reference = \" \".join([\n",
    "                    df_cleaned.loc[df_cleaned['ResponseID'] == resp_id, 'Responses'].values[0]\n",
    "                    for resp_id in filtered_responses_best.keys()\n",
    "                ])\n",
    "                final_prompt = (\n",
    "                    f\"Analyze the following text to understand its language, structure, and style:\\n\\n\"\n",
    "                    f\"{final_reference}\\n\\n\"\n",
    "                    f\"Now generate new text that mimics the above language, structure, and style, \"\n",
    "                    f\"while introducing new content related to the keywords: {', '.join(user_keywords)}.\"\n",
    "                )\n",
    "                final_mimicked_text = llama_generate_summary(final_prompt)\n",
    "                print(\"Mimicking Text:\")\n",
    "                print(final_mimicked_text)\n",
    "            else:\n",
    "                print(\"No relevant responses found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "    else:\n",
    "        print(\"Please enter at least one keyword.\")\n",
    "\n",
    "# Interactive User Input\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Open gvt\")\n",
    "    keyword1 = input(\"Enter the first keyword (or leave blank): \").strip()\n",
    "    keyword2 = input(\"Enter the second keyword (or leave blank): \").strip()\n",
    "    \n",
    "    generate_mimicking_text(keyword1, keyword2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
